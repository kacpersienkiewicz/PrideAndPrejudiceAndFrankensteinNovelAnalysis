{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will use the  Natural Language Toolkit (NLTK) to analyze the text in *Pride and Prejudice* and  *Frankenstein* find out the most common words. Common words like the, or and will be filtered out since it's obvious those sorts of words will be plentiful. Both of these novels came out in the 1810s and come from diametrically opposed genres: a novel of manners versus proto-science fiction, so it would be interesting to see how they used language differently at a surface level. \n",
    "\n",
    "First, the two novels will be scraped from **Project Gutenberg**. Luckily, the site offers them in plain text form already, which skips over extracting the plain text from HTML or some other format. This means that the text can be forced into all lowercase (to avoid pride and Pride being viewed as different words), and then analyzed. Analysis will include common words, sentence length, average word length, readability, and average syllables per word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['letter',\n",
       " '1',\n",
       " '_to',\n",
       " 'mrs',\n",
       " 'saville',\n",
       " 'england',\n",
       " '_',\n",
       " 'st',\n",
       " 'petersburgh',\n",
       " 'dec']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frankenstein = requests.get(\"https://www.gutenberg.org/cache/epub/84/pg84.txt\")\n",
    "Pride = requests.get(\"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\")\n",
    "\n",
    "FrankensteinText = Frankenstein.text.replace('\\r\\n', ' ').lower()[1380:]\n",
    "PrideText = Pride.text.replace('\\r\\n', ' ').lower()[35186:]\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "\n",
    "FrankensteinWords = tokenizer.tokenize(FrankensteinText)\n",
    "PrideWords = tokenizer.tokenize(PrideText)\n",
    "\n",
    "FrankensteinWords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text needs to be all lowercase so \"doctor\" and \"Doctor\" would not be counted as separate words. This does include the possiblity of proper nounds being counted alongside their non-proper version (cooper the job versus Cooper the surname), but this is unlikely to skew the data too much. There are also many new line characters throughout the text than needs to be removed, alongside a lengthy section before the story. This was fairly easily done with the replace and lower methods for the first two issues. The introductory segement was removed by using a character counter and a few rounds of guessing and checking. The counter made this a simple task. \n",
    "\n",
    "Then a tokenizer was used to extract the words from the text, courtesy of RegEx and NLTK. This is possible without using those methods by using the split method and a space as the separator, but this is far clunkier and is more error prone.\n",
    "\n",
    "Based on the beginning of Frankenstein there are many common words like \"I\", \"and\", \"in\" etc. that should be filtered out to properly compare the two texts. Luckily, NLTK has a method for this called stopwords. It is also evident some words are strangely written like \"_to\" and but this should have a minimal effect just like proper nouns and non-proper nouns being confused for each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "StrippedFrankensteinWords = [word for word in FrankensteinWords if word not in StopWords]\n",
    "StrippedPrideWords = [word for word in PrideWords if word not in StopWords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['letter',\n",
       " '1',\n",
       " '_to',\n",
       " 'mrs',\n",
       " 'saville',\n",
       " 'england',\n",
       " '_',\n",
       " 'st',\n",
       " 'petersburgh',\n",
       " 'dec']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StrippedFrankensteinWords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'single',\n",
       " 'man',\n",
       " 'possession',\n",
       " 'good',\n",
       " 'fortune',\n",
       " 'must',\n",
       " 'want']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StrippedPrideWords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the \"_to\" is kept but this shouldn't be a significant problem. Regardless, the list comprehension worked and the word lists are stripped of the stop words. Now the words can be counted and compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrankensteinCount = Counter(StrippedFrankensteinWords)\n",
    "PrideCount = Counter(StrippedPrideWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', 208),\n",
       " ('could', 198),\n",
       " ('would', 184),\n",
       " ('yet', 152),\n",
       " ('man', 137),\n",
       " ('father', 133),\n",
       " ('upon', 128),\n",
       " ('life', 116),\n",
       " ('may', 113),\n",
       " ('every', 109)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FrankensteinCount.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mr', 782),\n",
       " ('elizabeth', 634),\n",
       " ('could', 524),\n",
       " ('would', 467),\n",
       " ('darcy', 418),\n",
       " ('said', 403),\n",
       " ('mrs', 343),\n",
       " ('much', 328),\n",
       " ('bennet', 327),\n",
       " ('must', 316)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrideCount.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preliminary analysis shows a general difference in tone and outlook. For example, *Pride and Prejudice* contains honorifics like Mr., Mrs. and lady amongst the most common words as well as names such as Elizabeth, Darcy, and Bennet. On the other hand, *Frankenstein* has the general terms one, father, and man as more common than specific names. This is not to see there are no clear similiarities. Both include could, would, may, much, and shall in the most used words lists. These are likely common words for the time period that happened to not be stop words in NLTK's stopwords method. There is an argument to be made that the popularity of must, much, may, might and of honorifics, titles, and names corroborates the fact that *Pride and Prejudice* is a book of manners; likewise the commonplace impersonal words like one and man corroborates the fact that *Frankenstein* is a philosophical proto-science fiction text ( this is furthered by the popularity of life,death, mind and feelings).\n",
    "\n",
    "This is interesting to analyze, but there are other aspects of the text to analyze, such as average word and sentence length, as well as readability. The unstripped version of each work will be used for this comparison. Stop words like and would be useful for determining how long sentences and words are, as well as readability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
